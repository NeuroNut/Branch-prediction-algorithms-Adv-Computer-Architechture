{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbfe2834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting protobuf==3.20.3\n",
      "  Using cached protobuf-3.20.3-cp39-cp39-win_amd64.whl (904 kB)\n",
      "Installing collected packages: protobuf\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.19.6\n",
      "    Uninstalling protobuf-3.19.6:\n",
      "      Successfully uninstalled protobuf-3.19.6\n",
      "Successfully installed protobuf-3.20.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\adity\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\adity\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\adity\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\adity\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\adity\\anaconda3\\lib\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\n",
      "tensorboard 2.10.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\n",
      "mysql-connector-python 8.1.0 requires protobuf<=4.21.12,>=4.21.1, but you have protobuf 3.20.3 which is incompatible.\n",
      "grpcio-status 1.66.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.3 which is incompatible.\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\adity\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\adity\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\adity\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install protobuf==3.20.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31fe87b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (2087232769.py, line 276)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [19]\u001b[1;36m\u001b[0m\n\u001b[1;33m    if fusion_predictor:\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "# simulate_predictors.py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from collections import deque, defaultdict\n",
    "import os\n",
    "\n",
    "# --- Basic Predictor Implementations (Keep 1-Bit, 2-Bit, 2-Level, Tournament as before) ---\n",
    "class OneBitPredictor:\n",
    "    def __init__(self):\n",
    "        self.states = defaultdict(lambda: 0)\n",
    "    def predict(self, pc): return self.states[pc]\n",
    "    def update(self, pc, actual_outcome):\n",
    "        if self.predict(pc) != actual_outcome: self.states[pc] = 1 - self.states[pc]\n",
    "\n",
    "class TwoBitPredictor:\n",
    "    def __init__(self):\n",
    "        self.counters = defaultdict(lambda: 0)\n",
    "    def predict(self, pc): return 1 if self.counters[pc] >= 2 else 0\n",
    "    def update(self, pc, actual_outcome):\n",
    "        state = self.counters[pc]\n",
    "        if actual_outcome == 1: self.counters[pc] = min(state + 1, 3)\n",
    "        else: self.counters[pc] = max(state - 1, 0)\n",
    "\n",
    "class TwoLevelPredictor:\n",
    "    def __init__(self, ghr_bits=4, pht_size=16):\n",
    "        self.ghr_bits = ghr_bits\n",
    "        self.ghr = deque([0] * ghr_bits, maxlen=ghr_bits)\n",
    "        self.pht = defaultdict(lambda: 0)\n",
    "        self.pht_size = pht_size\n",
    "    def _get_pht_index(self, pc):\n",
    "        ghr_val = 0\n",
    "        for bit in self.ghr: ghr_val = (ghr_val << 1) | bit\n",
    "        pc_masked = pc & (self.pht_size - 1)\n",
    "        return pc_masked ^ ghr_val\n",
    "    def predict(self, pc): return 1 if self.pht[self._get_pht_index(pc)] >= 2 else 0\n",
    "    def update(self, pc, actual_outcome):\n",
    "        index = self._get_pht_index(pc)\n",
    "        state = self.pht[index]\n",
    "        if actual_outcome == 1: self.pht[index] = min(state + 1, 3)\n",
    "        else: self.pht[index] = max(state - 1, 0)\n",
    "        self.ghr.appendleft(actual_outcome)\n",
    "\n",
    "class TournamentPredictor:\n",
    "    def __init__(self, ghr_bits=4, pht_size=16, num_selectors=16):\n",
    "        self.local_predictor = TwoBitPredictor()\n",
    "        self.global_predictor = TwoLevelPredictor(ghr_bits, pht_size)\n",
    "        self.selectors = defaultdict(lambda: 0)\n",
    "        self.num_selectors = num_selectors\n",
    "    def _get_selector_index(self, pc): return pc & (self.num_selectors - 1)\n",
    "    def predict(self, pc):\n",
    "        selector_state = self.selectors[self._get_selector_index(pc)]\n",
    "        return self.global_predictor.predict(pc) if selector_state >= 2 else self.local_predictor.predict(pc)\n",
    "    def update(self, pc, actual_outcome):\n",
    "        local_pred = self.local_predictor.predict(pc)\n",
    "        global_pred = self.global_predictor.predict(pc)\n",
    "        self.local_predictor.update(pc, actual_outcome)\n",
    "        self.global_predictor.update(pc, actual_outcome)\n",
    "        local_correct = (local_pred == actual_outcome)\n",
    "        global_correct = (global_pred == actual_outcome)\n",
    "        selector_index = self._get_selector_index(pc)\n",
    "        selector_state = self.selectors[selector_index]\n",
    "        if local_correct and not global_correct: self.selectors[selector_index] = max(selector_state - 1, 0)\n",
    "        elif not local_correct and global_correct: self.selectors[selector_index] = min(selector_state + 1, 3)\n",
    "\n",
    "# --- Modified Fusion Predictor (Handles one ML model as predictor2) ---\n",
    "class FusionPredictorMLAware:\n",
    "    \"\"\"Combines predictions from one basic (predictor1) and one ML (predictor2) predictor.\"\"\"\n",
    "    def __init__(self, predictor1_instance, predictor2_instance, ml_model_name=\"ML Model\", num_selectors=16):\n",
    "        # Store INSTANCES of the base predictors\n",
    "        self.predictor1 = predictor1_instance\n",
    "        self.predictor2 = predictor2_instance # This is the Keras model instance\n",
    "        self.p1_name = predictor1_instance.__class__.__name__\n",
    "        self.p2_name = ml_model_name # Use provided name for ML\n",
    "\n",
    "        # Selector chooses predictor1 (0,1) or predictor2 (2,3)\n",
    "        self.selectors = defaultdict(lambda: 0) # Default to predictor1\n",
    "        self.num_selectors = num_selectors\n",
    "\n",
    "    def _get_selector_index(self, pc):\n",
    "         return pc & (self.num_selectors - 1)\n",
    "\n",
    "    # PREDICT method now needs the history buffer for the ML model\n",
    "    def predict(self, pc, history_buffer, history_window_size):\n",
    "        selector_index = self._get_selector_index(pc)\n",
    "        selector_state = self.selectors[selector_index]\n",
    "\n",
    "        # --- Get Prediction 1 (Basic) ---\n",
    "        pred1 = self.predictor1.predict(pc)\n",
    "\n",
    "        # --- Get Prediction 2 (ML) ---\n",
    "        pred2 = 0 # Default prediction if ML can't run yet\n",
    "        can_predict_ml = (history_buffer is not None and len(history_buffer) >= history_window_size)\n",
    "        if can_predict_ml:\n",
    "            current_window = np.array(history_buffer).reshape(1, history_window_size, 1)\n",
    "            # Use the stored ML model instance directly\n",
    "            prob_taken = self.predictor2.predict(current_window, verbose=0)[0][0]\n",
    "            pred2 = 1 if prob_taken >= 0.5 else 0\n",
    "\n",
    "        # --- Choose based on selector ---\n",
    "        if selector_state < 2: # Prefer Predictor 1\n",
    "            return pred1\n",
    "        else: # Prefer Predictor 2\n",
    "            # If ML couldn't predict, fall back to predictor 1's prediction maybe?\n",
    "            # Or just return the default pred2 (0). Let's return pred2.\n",
    "            return pred2\n",
    "\n",
    "    # UPDATE method also needs history buffer to determine ML prediction correctness\n",
    "    def update(self, pc, actual_outcome, history_buffer, history_window_size):\n",
    "        # --- Re-calculate predictions based on state *before* update ---\n",
    "        # Get P1 prediction\n",
    "        pred1 = self.predictor1.predict(pc)\n",
    "\n",
    "        # Get P2 (ML) prediction for correctness check\n",
    "        pred2 = 0 # Default if cannot predict\n",
    "        can_predict_ml = (history_buffer is not None and len(history_buffer) >= history_window_size)\n",
    "        if can_predict_ml:\n",
    "             current_window = np.array(history_buffer).reshape(1, history_window_size, 1)\n",
    "             prob_taken = self.predictor2.predict(current_window, verbose=0)[0][0]\n",
    "             pred2 = 1 if prob_taken >= 0.5 else 0\n",
    "\n",
    "        # --- Update the basic predictor's internal state ---\n",
    "        self.predictor1.update(pc, actual_outcome)\n",
    "        # (ML predictor has no state update here)\n",
    "\n",
    "        # --- Update the selector ---\n",
    "        # Check correctness based on the predictions made *before* the update\n",
    "        p1_correct = (pred1 == actual_outcome)\n",
    "        # Only consider p2 correct if it could actually make a prediction\n",
    "        p2_correct = (pred2 == actual_outcome) and can_predict_ml\n",
    "\n",
    "        selector_index = self._get_selector_index(pc)\n",
    "        selector_state = self.selectors[selector_index]\n",
    "\n",
    "        # Adjust selector state\n",
    "        if p1_correct and not p2_correct:\n",
    "            # P1 right, P2 wrong/unable -> Decrement (prefer P1)\n",
    "            self.selectors[selector_index] = max(selector_state - 1, 0)\n",
    "        elif not p1_correct and p2_correct:\n",
    "            # P2 right, P1 wrong -> Increment (prefer P2)\n",
    "            self.selectors[selector_index] = min(selector_state + 1, 3)\n",
    "        # If both right, both wrong, or P2 unable & P1 wrong, selector state remains unchanged\n",
    "# --- Simplified BranchNet Implementations (Keras/TF) ---\n",
    "\n",
    "def build_simple_branchnet_cnn(history_window_size, num_features=1):\n",
    "    \"\"\"Builds a purely CNN-based model, slightly enhanced.\"\"\"\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            keras.Input(shape=(history_window_size, num_features)),\n",
    "            layers.Conv1D(filters=32, kernel_size=5, padding='causal', activation=\"relu\"),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Conv1D(filters=64, kernel_size=5, padding='causal', activation=\"relu\"),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.MaxPooling1D(pool_size=2), # Added Pooling\n",
    "            layers.Conv1D(filters=64, kernel_size=3, padding='causal', activation=\"relu\"), # Added Layer\n",
    "            layers.GlobalAveragePooling1D(),\n",
    "            layers.Dense(32, activation=\"relu\"),\n",
    "            layers.Dropout(0.3),\n",
    "            layers.Dense(1, activation=\"sigmoid\"),\n",
    "        ]\n",
    "    )\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001) # Maybe default LR is fine here\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "def build_simple_branchnet_lstm(history_window_size, num_features=1):\n",
    "    \"\"\"Builds a CNN+LSTM model.\"\"\"\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            keras.Input(shape=(history_window_size, num_features)),\n",
    "            layers.Conv1D(filters=32, kernel_size=5, padding='causal', activation=\"relu\"),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Conv1D(filters=64, kernel_size=5, padding='causal', activation=\"relu\"),\n",
    "            layers.BatchNormalization(),\n",
    "            # Feed sequence output of CNNs to LSTM\n",
    "            layers.LSTM(32, return_sequences=False), # return_sequences=False gives only the last output\n",
    "            layers.Dense(32, activation=\"relu\"),\n",
    "            layers.Dropout(0.3),\n",
    "            layers.Dense(1, activation=\"sigmoid\"),\n",
    "        ]\n",
    "    )\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.0005) # Often lower LR for RNNs\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "def build_simple_branchnet_transformer(history_window_size, num_features=1, head_size=64, num_heads=4, ff_dim=32, num_transformer_blocks=1):\n",
    "    \"\"\"Builds a simple Transformer Encoder based model.\"\"\"\n",
    "    inputs = keras.Input(shape=(history_window_size, num_features))\n",
    "    x = inputs\n",
    "    for _ in range(num_transformer_blocks):\n",
    "        # Attention and Normalization\n",
    "        attention_output = layers.MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=0.1)(x, x)\n",
    "        x = layers.Add()([x, attention_output])\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "        # Feed Forward Part\n",
    "        ffn_output = layers.Dense(ff_dim, activation=\"relu\")(x)\n",
    "        ffn_output = layers.Dense(num_features)(ffn_output) # Project back to input dims\n",
    "        x = layers.Add()([x, ffn_output])\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "\n",
    "    # Pooling or Flattening before final classification\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    x = layers.Dense(16, activation=\"relu\")(x)\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.0005)\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "# --- Simulation Function ---\n",
    "\n",
    "# --- Simulation Function (Modified for ML-aware Fusion) ---\n",
    "\n",
    "def simulate_predictors(full_history, basic_predictors, ml_models, fusion_predictor=None, history_window_size=16):\n",
    "    \n",
    "    \"\"\"Simulates predictors and returns their accuracy. Assumes fusion_predictor uses ML.\"\"\"\n",
    "    # Initialize results dictionaries\n",
    "    results = {name: {'correct': 0, 'total': 0} for name in basic_predictors}\n",
    "    results.update({name: {'correct': 0, 'total': 0} for name in ml_models})\n",
    "    \n",
    "    \n",
    "    if fusion_predictor:\n",
    "        # Use the ML model name provided during fusion predictor init\n",
    "        fusion_label = f\"Fusion ({fusion_predictor.p1_name}+{fusion_predictor.p2_name})\"\n",
    "        results[fusion_label] = {'correct': 0, 'total': 0}\n",
    "        \n",
    "    branch_pc = 0xABC # Fixed PC\n",
    "\n",
    "    history_buffer = deque([0] * history_window_size, maxlen=history_window_size) # For ML models\n",
    "\n",
    "    for i in range(len(full_history)):\n",
    "        actual_outcome = full_history[i]\n",
    "        can_predict_ml_this_step = (i >= history_window_size)\n",
    "\n",
    "        # --- Predict with Fusion Predictor FIRST ---\n",
    "        \n",
    "        \n",
    "        if fusion_predictor:\n",
    "            fusion_pred = fusion_predictor.predict(branch_pc, history_buffer, history_window_size)\n",
    "            \n",
    "            # *** FIXED LOGIC ***\n",
    "            # Always increment total for fusion once a prediction is made\n",
    "            results[fusion_label]['total'] += 1\n",
    "            \n",
    "            if fusion_pred == actual_outcome:\n",
    "                results[fusion_label]['correct'] += 1\n",
    "            # No need for complex logic based on who was chosen here,\n",
    "            # just evaluate the final fusion prediction.\n",
    "\n",
    "\n",
    "        # --- Predict with Standalone Basic Predictors ---\n",
    "        basic_preds_this_step = {}\n",
    "        for name, predictor in basic_predictors.items():\n",
    "            basic_preds_this_step[name] = predictor.predict(branch_pc) # Store prediction\n",
    "            if basic_preds_this_step[name] == actual_outcome:\n",
    "                results[name]['correct'] += 1\n",
    "            results[name]['total'] += 1\n",
    "\n",
    "\n",
    "        # --- Predict with Standalone ML Models ---\n",
    "        if can_predict_ml_this_step:\n",
    "#             current_window = np.array(history_buffer).reshape(1, history_window_size, 1)\n",
    "#             for name, model in ml_models.items():\n",
    "#                 prob_taken = model.predict(current_window, verbose=0)[0][0]\n",
    "#                 ml_pred = 1 if prob_taken >= 0.5 else 0\n",
    "#                 if ml_pred == actual_outcome: results[name]['correct'] += 1\n",
    "#                 results[name]['total'] += 1 # Total increments only after warm-up\n",
    "\n",
    "\n",
    "        # --- UPDATE Phase ---\n",
    "        # Update Fusion Predictor (which internally updates its P1 basic predictor)\n",
    "        if fusion_predictor:\n",
    "            # Pass the current history buffer state for correctness check inside update\n",
    "            fusion_predictor.update(branch_pc, actual_outcome, history_buffer, history_window_size)\n",
    "\n",
    "        # Update Standalone Basic Predictors\n",
    "        for name, predictor in basic_predictors.items():\n",
    "            predictor.update(branch_pc, actual_outcome)\n",
    "\n",
    "\n",
    "        # --- Update History Buffer for NEXT iteration's ML predictions ---\n",
    "        history_buffer.append(actual_outcome)\n",
    "\n",
    "    # Calculate final accuracies\n",
    "    accuracies = {}\n",
    "    for name, res in results.items():\n",
    "        if res['total'] > 0: accuracies[name] = res['correct'] / res['total']\n",
    "        else: accuracies[name] = 0.0\n",
    "\n",
    "    return accuracies\n",
    "\n",
    "# --- Main Execution ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    HISTORY_WINDOW_SIZE = 16\n",
    "    DATA_FILE = 'branchnet_training_data.npz'\n",
    "\n",
    "    # 1. Load Data\n",
    "    if not os.path.exists(DATA_FILE):\n",
    "        print(f\"Data file {DATA_FILE} not found. Run generate_data.py (with noise=0).\")\n",
    "        exit()\n",
    "    print(f\"Loading data from {DATA_FILE}...\")\n",
    "    data = np.load(DATA_FILE)\n",
    "    X_train_full = data['X']\n",
    "    y_train_full = data['y']\n",
    "    full_history = data['full_history']\n",
    "    print(f\"Loaded full history length: {len(full_history)}\")\n",
    "\n",
    "    # Split training data for ML models\n",
    "    split_idx = int(len(X_train_full) * 0.8)\n",
    "    X_val, y_val = X_train_full[split_idx:], y_train_full[split_idx:]\n",
    "    X_train, y_train = X_train_full[:split_idx], y_train_full[:split_idx]\n",
    "\n",
    "    # 2. Build and Train ML Models\n",
    "    ml_models = {}\n",
    "    epochs_to_train = 15 # Adjust as needed\n",
    "\n",
    "    print(\"\\n--- Building and Training ML Models ---\")\n",
    "    # --- CNN ---\n",
    "    print(\"\\nTraining Simple_BranchNet_CNN...\")\n",
    "    ml_models['BranchNet_CNN'] = build_simple_branchnet_cnn(HISTORY_WINDOW_SIZE)\n",
    "    ml_models['BranchNet_CNN'].fit(X_train, y_train, epochs=epochs_to_train, batch_size=32, validation_data=(X_val, y_val), verbose=0)\n",
    "    print(\"CNN Training Complete.\")\n",
    "\n",
    "    # --- CNN+LSTM ---\n",
    "    print(\"\\nTraining Simple_BranchNet_LSTM...\")\n",
    "    ml_models['BranchNet_LSTM'] = build_simple_branchnet_lstm(HISTORY_WINDOW_SIZE)\n",
    "    ml_models['BranchNet_LSTM'].fit(X_train, y_train, epochs=epochs_to_train, batch_size=32, validation_data=(X_val, y_val), verbose=0)\n",
    "    print(\"LSTM Training Complete.\")\n",
    "\n",
    "    # --- Transformer ---\n",
    "    print(\"\\nTraining Simple_BranchNet_Transformer...\")\n",
    "    ml_models['BranchNet_Transformer'] = build_simple_branchnet_transformer(HISTORY_WINDOW_SIZE)\n",
    "    ml_models['BranchNet_Transformer'].fit(X_train, y_train, epochs=epochs_to_train, batch_size=32, validation_data=(X_val, y_val), verbose=0)\n",
    "    print(\"Transformer Training Complete.\")\n",
    "\n",
    "\n",
    "    # 3. Initialize Basic Predictors (These will be used by Fusion)\n",
    "    # We need fresh instances because the simulation modifies their state.\n",
    "    basic_predictors_standalone = {\n",
    "        \"1-Bit\": OneBitPredictor(),\n",
    "        \"2-Bit\": TwoBitPredictor(),\n",
    "        \"2-Level\": TwoLevelPredictor(ghr_bits=4),\n",
    "        \"Tournament\": TournamentPredictor(ghr_bits=4)\n",
    "    }\n",
    "\n",
    "    # Initialize the specific instances for the ML-Aware Fusion predictor\n",
    "    # ***** CHANGE THIS PART *****\n",
    "    p1_for_fusion = TwoLevelPredictor(ghr_bits=4)     # Basic predictor (e.g., 2-Level)\n",
    "    p2_for_fusion = ml_models['BranchNet_LSTM']       # The *trained Keras model* instance\n",
    "    ml_model_label = 'BranchNet_LSTM'                 # Name for labeling\n",
    "    # ***************************\n",
    "\n",
    "    # Initialize the Fusion predictor (use the new class name)\n",
    "    fusion_predictor_instance = FusionPredictorMLAware(\n",
    "        p1_for_fusion,\n",
    "        p2_for_fusion,\n",
    "        ml_model_name=ml_model_label # Pass the name\n",
    "    )\n",
    "    print(f\"\\nFusion Predictor will combine: {fusion_predictor_instance.p1_name} and {fusion_predictor_instance.p2_name}\")\n",
    "\n",
    "\n",
    "    # 4. Run Simulation\n",
    "    print(\"\\nSimulating all predictors...\")\n",
    "    accuracies = simulate_predictors(\n",
    "        full_history,\n",
    "        basic_predictors_standalone, # Pass the dict for standalone comparison\n",
    "        ml_models,                   # Pass the dict of trained ML models\n",
    "        fusion_predictor=fusion_predictor_instance, # Pass the ML-aware fusion instance\n",
    "        history_window_size=HISTORY_WINDOW_SIZE\n",
    "    )\n",
    "\n",
    "    # 5. Print Results\n",
    "    print(\"\\n--- Simulation Results ---\")\n",
    "    # ... (Print basic predictors) ...\n",
    "    # ... (Print ML models) ...\n",
    "    # Print basic predictors first\n",
    "    for name in [\"1-Bit\", \"2-Bit\", \"2-Level\", \"Tournament\"]:\n",
    "         print(f\"{name:>20}: {accuracies.get(name, 0.0):.4f} Accuracy\")\n",
    "    # Print ML models\n",
    "    for name in sorted(ml_models.keys()):\n",
    "        print(f\"{name:>20}: {accuracies.get(name, 0.0):.4f} Accuracy\")\n",
    "    # Generate the label used in results dict\n",
    "    fusion_label = f\"Fusion ({fusion_predictor_instance.p1_name}+{fusion_predictor_instance.p2_name})\"\n",
    "    if fusion_label in accuracies:\n",
    "        print(f\"{fusion_label:>20}: {accuracies[fusion_label]:.4f} Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46dcda25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               1-Bit: 0.4840 Accuracy\n",
      "               2-Bit: 0.4290 Accuracy\n",
      "             2-Level: 0.6480 Accuracy\n",
      "          Tournament: 0.5900 Accuracy\n",
      "       BranchNet_CNN: 0.7134 Accuracy\n",
      "      BranchNet_LSTM: 1.0000 Accuracy\n",
      "BranchNet_Transformer: 0.5437 Accuracy\n"
     ]
    }
   ],
   "source": [
    "for name in [\"1-Bit\", \"2-Bit\", \"2-Level\", \"Tournament\"]:\n",
    "    print(f\"{name:>20}: {accuracies.get(name, 0.0):.4f} Accuracy\")\n",
    "    # Print ML models\n",
    "for name in sorted(ml_models.keys()):\n",
    "    print(f\"{name:>20}: {accuracies.get(name, 0.0):.4f} Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e3698a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X', 'y', 'full_history']\n",
      "[[[0]\n",
      "  [0]\n",
      "  [0]\n",
      "  ...\n",
      "  [1]\n",
      "  [0]\n",
      "  [1]]\n",
      "\n",
      " [[0]\n",
      "  [0]\n",
      "  [1]\n",
      "  ...\n",
      "  [0]\n",
      "  [1]\n",
      "  [1]]\n",
      "\n",
      " [[0]\n",
      "  [1]\n",
      "  [1]\n",
      "  ...\n",
      "  [1]\n",
      "  [1]\n",
      "  [0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0]\n",
      "  [0]\n",
      "  [0]\n",
      "  ...\n",
      "  [0]\n",
      "  [0]\n",
      "  [0]]\n",
      "\n",
      " [[0]\n",
      "  [0]\n",
      "  [1]\n",
      "  ...\n",
      "  [0]\n",
      "  [0]\n",
      "  [1]]\n",
      "\n",
      " [[0]\n",
      "  [1]\n",
      "  [1]\n",
      "  ...\n",
      "  [0]\n",
      "  [1]\n",
      "  [1]]]\n",
      "[1 0 0 1 0 1 1 1 0 1 0 0 0 1 0 1 1 1 0 1 0 1 0 0 0 1 1 1 1 1 0 0 0 1 0 1 1\n",
      " 1 0 1 1 0 0 1 0 0 1 0 1 1 1 0 1 0 1 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 1 0 1 1\n",
      " 1 1 1 0 0 1 0 0 0 1 0 1 1 1 0 0 0 0 0 1 1 1 0 1 0 0 0 1 0 0 1 1 0 0 1 0 1\n",
      " 0 1 0 0 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 1 0 1 1 0 0 1 1 0 1 1 0 0 1 1 0 1\n",
      " 1 0 0 1 1 0 1 1 0 0 1 1 0 1 1 0 0 1 1 0 1 1 0 0 1 1 0 1 1 0 1 1 1 0 1 0 0\n",
      " 0 1 0 1 1 1 0 1 0 1 0 1 0 1 0 1 1 1 0 1 1 0 0 0 0 0 1 1 1 1 0 0 0 0 0 1 0\n",
      " 0 1 1 1 1 1 0 1 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1 1 1 1 0 0 1 0 0 1 1 0 1 0 0\n",
      " 0 1 0 1 1 0 1 0 0 0 1 0 0 1 1 0 0 1 0 1 1 1 0 1 0 0 1 1 0 1 0 1 0 0 0 1 0\n",
      " 1 1 1 1 1 0 0 0 1 0 0 1 1 0 1 1 0 1 1 0 0 1 0 0 0 1 0 1 1 1 0 0 0 0 0 1 1\n",
      " 1 0 1 0 0 0 1 0 0 1 1 0 1 1 1 1 1 0 0 0 0 0 0 1 1 1 1 1 0 1 0 0 0 1 0 1 0\n",
      " 1 0 1 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 1 0 1 1 1 0 1 0\n",
      " 0 0 1 0 0 1 1 0 1 1 1 1 1 1 0 0 0 0 1 1 1 1 1 0 0 1 0 0 1 1 0 1 0 0 0 1 0\n",
      " 1 1 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1 1 1 0 1 0 1 1 1 0 1 0 0 0 0 0 1 1 1 1 1\n",
      " 1 0 1 0 1 0 1 1 1 0 0 0 0 0 0 1 1 1 1 1 0 1 0 0 0 1 0 1 0 1 0 1 0 1 0 0 0\n",
      " 1 0 1 1 1 1 1 0 0 0 0 1 0 1 1 1 0 1 0 1 0 1 0 1 0 1 1 1 0 1 0 0 0 1 0 1 1\n",
      " 1 0 1 1 0 0 1 0 0 1 0 0 1 1 0 1 1 0 0 1 1 1 0 1 1 0 0 1 0 0 1 0 0 1 1 0 1\n",
      " 1 1 1 1 0 0 0 0 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 0 0 0 0 1 1 0 1 1 1 1 1 0 1\n",
      " 0 0 1 1 0 1 0 0 0 1 0 1 1 0 0 1 0 0 1 1 1 1 1 1 0 0 0 1 0 1 1 1 0 1 1 0 0\n",
      " 0 0 0 0 0 1 1 1 1 1 0 1 0 0 0 1 0 1 0 1 0 1 0 1 0 0 0 1 0 1 1 1 1 1 0 0 1\n",
      " 0 1 0 1 0 1 0 1 0 0 0 1 0 1 1 1 1 1 0 0 0 0 1 1 1 1 1 0 0 0 1 0 1 1 1 0 1\n",
      " 1 0 0 1 0 0 1 0 0 1 1 0 1 1 1 1 0 0 0 0 0 1 1 1 1 1 0 0 1 0 0 1 0 0 1 0 0\n",
      " 1 1 0 1 1 1 1 1 0 0 0 1 1 1 1 1 0 0 0 1 0 1 1 1 1 1 1 0 0 0 0 0 1 0 1 1 1\n",
      " 0 1 0 0 0 1 0 1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 0 0 0 0 1\n",
      " 1 0 1 1 1 0 1 0 1 0 1 0 1 1 1 0 0 1 0 0 1 1 1 1 1 0 0 0 0 0 1 0 1 1 1 0 1\n",
      " 0 0 0 1 0 0 0 1 0 1 1 1 1 0 0 1 0 0 1 1 1 1 1 0 0 0 0 1 1 1 1 1 0 0 0 0 0\n",
      " 1 1 1 1 0 0 0 0 0 1 1 0 1 1 0 0 1 0 0 1 1 0 1 1 0 1 1 0 0 1 0 0 0 1 0 1 1\n",
      " 1 0 0 0 0 0 1 1 1 0 1 0 0 1 1 0 0 0 0 1 1 1]\n",
      "[0 0 0 1 1 1 1 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1 1 1 0 1 0 0 0 1 0 1 1 1 0 1 0\n",
      " 1 0 0 0 1 1 1 1 1 0 0 0 1 0 1 1 1 0 1 1 0 0 1 0 0 1 0 1 1 1 0 1 0 1 0 0 0\n",
      " 1 0 1 0 1 0 1 0 0 0 0 0 1 0 1 1 1 1 1 0 0 1 0 0 0 1 0 1 1 1 0 0 0 0 0 1 1\n",
      " 1 0 1 0 0 0 1 0 0 1 1 0 0 1 0 1 0 1 0 0 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 1\n",
      " 0 1 1 0 0 1 1 0 1 1 0 0 1 1 0 1 1 0 0 1 1 0 1 1 0 0 1 1 0 1 1 0 0 1 1 0 1\n",
      " 1 0 0 1 1 0 1 1 0 1 1 1 0 1 0 0 0 1 0 1 1 1 0 1 0 1 0 1 0 1 0 1 1 1 0 1 1\n",
      " 0 0 0 0 0 1 1 1 1 0 0 0 0 0 1 0 0 1 1 1 1 1 0 1 0 0 0 1 1 1 0 1 0 0 0 0 0\n",
      " 1 1 1 1 1 0 0 1 0 0 1 1 0 1 0 0 0 1 0 1 1 0 1 0 0 0 1 0 0 1 1 0 0 1 0 1 1\n",
      " 1 0 1 0 0 1 1 0 1 0 1 0 0 0 1 0 1 1 1 1 1 0 0 0 1 0 0 1 1 0 1 1 0 1 1 0 0\n",
      " 1 0 0 0 1 0 1 1 1 0 0 0 0 0 1 1 1 0 1 0 0 0 1 0 0 1 1 0 1 1 1 1 1 0 0 0 0\n",
      " 0 0 1 1 1 1 1 0 1 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 1 0\n",
      " 1 0 1 0 1 0 0 0 1 0 1 1 1 0 1 0 0 0 1 0 0 1 1 0 1 1 1 1 1 1 0 0 0 0 1 1 1\n",
      " 1 1 0 0 1 0 0 1 1 0 1 0 0 0 1 0 1 1 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1 1 1 0 1\n",
      " 0 1 1 1 0 1 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1 0 1 1 1 0 0 0 0 0 0 1 1 1 1 1 0\n",
      " 1 0 0 0 1 0 1 0 1 0 1 0 1 0 0 0 1 0 1 1 1 1 1 0 0 0 0 1 0 1 1 1 0 1 0 1 0\n",
      " 1 0 1 0 1 1 1 0 1 0 0 0 1 0 1 1 1 0 1 1 0 0 1 0 0 1 0 0 1 1 0 1 1 0 0 1 1\n",
      " 1 0 1 1 0 0 1 0 0 1 0 0 1 1 0 1 1 1 1 1 0 0 0 0 1 1 1 1 1 0 0 1 0 0 1 1 1\n",
      " 1 0 0 0 0 0 1 1 0 1 1 1 1 1 0 1 0 0 1 1 0 1 0 0 0 1 0 1 1 0 0 1 0 0 1 1 1\n",
      " 1 1 1 0 0 0 1 0 1 1 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 1 0 1 0 0 0 1 0 1 0 1 0\n",
      " 1 0 1 0 0 0 1 0 1 1 1 1 1 0 0 1 0 1 0 1 0 1 0 1 0 0 0 1 0 1 1 1 1 1 0 0 0\n",
      " 0 1 1 1 1 1 0 0 0 1 0 1 1 1 0 1 1 0 0 1 0 0 1 0 0 1 1 0 1 1 1 1 0 0 0 0 0\n",
      " 1 1 1 1 1 0 0 1 0 0 1 0 0 1 0 0 1 1 0 1 1 1 1 1 0 0 0 1 1 1 1 1 0 0 0 1 0\n",
      " 1 1 1 1 1 1 0 0 0 0 0 1 0 1 1 1 0 1 0 0 0 1 0 1 1 1 1 1 0 0 0 0 0 1 1 1 1\n",
      " 1 0 0 1 0 0 1 1 1 1 0 0 0 0 0 1 1 0 1 1 1 0 1 0 1 0 1 0 1 1 1 0 0 1 0 0 1\n",
      " 1 1 1 1 0 0 0 0 0 1 0 1 1 1 0 1 0 0 0 1 0 0 0 1 0 1 1 1 1 0 0 1 0 0 1 1 1\n",
      " 1 1 0 0 0 0 1 1 1 1 1 0 0 0 0 0 1 1 1 1 0 0 0 0 0 1 1 0 1 1 0 0 1 0 0 1 1\n",
      " 0 1 1 0 1 1 0 0 1 0 0 0 1 0 1 1 1 0 0 0 0 0 1 1 1 0 1 0 0 1 1 0 0 0 0 1 1\n",
      " 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the .npz file\n",
    "data = np.load('branchnet_training_data.npz')\n",
    "\n",
    "# Access the arrays within the .npz file\n",
    "# .npz files are like dictionaries, so you access elements by their keys\n",
    "print(data.files) # Prints the names of the arrays stored in the file\n",
    "\n",
    "#Access a specific array\n",
    "array1 = data['X'] # if the array was saved without a specific name\n",
    "array2 = data['y'] # if the array was saved with the name 'name_of_your_array'\n",
    "array3 = data['full_history']\n",
    "# Print the arrays\n",
    "print(array1)\n",
    "print(array2)\n",
    "print(array3)\n",
    "\n",
    "# Close the file\n",
    "data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133d22f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
